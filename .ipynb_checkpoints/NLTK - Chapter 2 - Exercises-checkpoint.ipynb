{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Create a variable phrase containing a list of words. Review the operations described in the previous chapter, including addition, multiplication, indexing, slicing, and sorting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:\n",
      " oi, tudo bem, como vai voce \n",
      "\n",
      "\n",
      "addition:\n",
      " oi, tudo bem, como vai voce \n",
      "tudo bem\n",
      "\n",
      "\n",
      "multiplication:\n",
      " oi, tudo bem, como vai voce oi, tudo bem, como vai voce \n",
      "\n",
      "\n",
      "indexing:\n",
      " ,\n",
      "\n",
      "\n",
      "slicing:\n",
      " tudo \n",
      "\n",
      "\n",
      "sorting:\n",
      " [' ', ' ', ' ', ' ', ' ', ' ', ',', ',', 'a', 'b', 'c', 'c', 'd', 'e', 'e', 'i', 'i', 'm', 'm', 'o', 'o', 'o', 'o', 'o', 't', 'u', 'v', 'v']\n",
      "\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "phrase = 'oi, tudo bem, como vai voce '\n",
    "print('original:\\n',phrase)\n",
    "print('\\n')\n",
    "\n",
    "dialogue = phrase + '\\ntudo bem'\n",
    "print('addition:\\n', dialogue)\n",
    "print('\\n')\n",
    "\n",
    "repeatQuestion = phrase*2\n",
    "print('multiplication:\\n', repeatQuestion)\n",
    "print('\\n')\n",
    "\n",
    "indexComma = phrase[2]\n",
    "print('indexing:\\n', indexComma)\n",
    "print('\\n')\n",
    "\n",
    "justTudo = phrase[4:9]\n",
    "print('slicing:\\n', justTudo)\n",
    "print('\\n')\n",
    "\n",
    "print('sorting:\\n', sorted(phrase))\n",
    "print('\\n')\n",
    "\n",
    "print('end')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "☼ Use the corpus module to explore austen-persuasion.txt. How many word tokens does this book have? How many word types?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of tokens =  192427\n",
      "number of word types: 7811\n",
      "\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "emma = gutenberg.words('austen-emma.txt')\n",
    "\n",
    "print('number of tokens = ', len(emma))\n",
    "\n",
    "uniqueWords = set(emma)\n",
    "print('number of word types:', len(uniqueWords))\n",
    "\n",
    "print('\\nend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Use the Brown corpus reader nltk.corpus.brown.words() or the Web text corpus reader nltk.corpus.webtext.words() to access some sample text in two different genres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-112f0fb4ceba>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-112f0fb4ceba>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    samples = word for currentID in brown.fileids('mystery')\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "\n",
    "sampleMystery = brown.words(categories = 'mystery')\n",
    "samples = word for currentID in brown.fileids('mystery')\n",
    "print('mistery: ', sampleMystery)\n",
    "\n",
    "sampleSciFi = brown.words(categories = 'science_fiction')\n",
    "print('science fiction: ',sampleSciFi)\n",
    "\n",
    "print('\\nend')\n",
    "\n",
    "brown.fileids('news')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Read in the texts of the State of the Union addresses, using the state_union corpus reader. Count occurrences of men, women, and people in each document. What has happened to the usage of these words over time?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ Investigate the holonym-meronym relations for some nouns. Remember that there are three kinds of holonym-meronym relation, so you need to use: member_meronyms(),  part_meronyms(), substance_meronyms(), member_holonyms(), part_holonyms(), and substance_holonyms()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☼ In the discussion of comparative wordlists, we created an object called translate which you could look up using words in both German and Spanish in order to get corresponding words in English. What problem might arise with this approach? Can you suggest a way to avoid this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
